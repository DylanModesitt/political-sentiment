_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
Train on 12231 samples, validate on 1359 samples
Epoch 1/10

  128/12231 [..............................] - ETA: 5:23 - loss: 0.8489 - acc: 0.5391
  256/12231 [..............................] - ETA: 3:12 - loss: 0.9748 - acc: 0.5547
  384/12231 [..............................] - ETA: 2:28 - loss: 1.0245 - acc: 0.5026
  512/12231 [>.............................] - ETA: 2:05 - loss: 0.9904 - acc: 0.5000
  640/12231 [>.............................] - ETA: 1:52 - loss: 0.9627 - acc: 0.5156
  768/12231 [>.............................] - ETA: 1:45 - loss: 0.9438 - acc: 0.5299
  896/12231 [=>............................] - ETA: 1:39 - loss: 0.9349 - acc: 0.5357
 1024/12231 [=>............................] - ETA: 1:34 - loss: 0.9246 - acc: 0.5371
 1152/12231 [=>............................] - ETA: 1:31 - loss: 0.9152 - acc: 0.5382
 1280/12231 [==>...........................] - ETA: 1:29 - loss: 0.9111 - acc: 0.5273
 1408/12231 [==>...........................] - ETA: 1:26 - loss: 0.9078 - acc: 0.5206
 1536/12231 [==>...........................] - ETA: 1:23 - loss: 0.9021 - acc: 0.5247
 1664/12231 [===>..........................] - ETA: 1:21 - loss: 0.8977 - acc: 0.5264
 1792/12231 [===>..........................] - ETA: 1:19 - loss: 0.8932 - acc: 0.5273
 1920/12231 [===>..........................] - ETA: 1:19 - loss: 0.8886 - acc: 0.5328
 2048/12231 [====>.........................] - ETA: 1:17 - loss: 0.8873 - acc: 0.5317
 2176/12231 [====>.........................] - ETA: 1:16 - loss: 0.8850 - acc: 0.5322
 2304/12231 [====>.........................] - ETA: 1:15 - loss: 0.8835 - acc: 0.5330
 2432/12231 [====>.........................] - ETA: 1:14 - loss: 0.8821 - acc: 0.5296
 2560/12231 [=====>........................] - ETA: 1:12 - loss: 0.8807 - acc: 0.5277
 2688/12231 [=====>........................] - ETA: 1:11 - loss: 0.8798 - acc: 0.5268
 2816/12231 [=====>........................] - ETA: 1:10 - loss: 0.8790 - acc: 0.5263
 2944/12231 [======>.......................] - ETA: 1:08 - loss: 0.8764 - acc: 0.5289
 3072/12231 [======>.......................] - ETA: 1:07 - loss: 0.8761 - acc: 0.5270
 3200/12231 [======>.......................] - ETA: 1:05 - loss: 0.8751 - acc: 0.5269
 3328/12231 [=======>......................] - ETA: 1:04 - loss: 0.8731 - acc: 0.5291
 3456/12231 [=======>......................] - ETA: 1:03 - loss: 0.8716 - acc: 0.5301
 3584/12231 [=======>......................] - ETA: 1:01 - loss: 0.8708 - acc: 0.5312
 3712/12231 [========>.....................] - ETA: 1:03 - loss: 0.8688 - acc: 0.5337
 3840/12231 [========>.....................] - ETA: 1:05 - loss: 0.8677 - acc: 0.5352
 3968/12231 [========>.....................] - ETA: 1:04 - loss: 0.8670 - acc: 0.5348
 4096/12231 [=========>....................] - ETA: 1:04 - loss: 0.8654 - acc: 0.5361
 4224/12231 [=========>....................] - ETA: 1:03 - loss: 0.8634 - acc: 0.5379
 4352/12231 [=========>....................] - ETA: 1:02 - loss: 0.8622 - acc: 0.5381
 4480/12231 [=========>....................] - ETA: 1:01 - loss: 0.8614 - acc: 0.5384
 4608/12231 [==========>...................] - ETA: 1:00 - loss: 0.8605 - acc: 0.5395
 4736/12231 [==========>...................] - ETA: 58s - loss: 0.8598 - acc: 0.5403 
 4864/12231 [==========>...................] - ETA: 57s - loss: 0.8583 - acc: 0.5419
 4992/12231 [===========>..................] - ETA: 56s - loss: 0.8583 - acc: 0.5419
 5120/12231 [===========>..................] - ETA: 55s - loss: 0.8562 - acc: 0.5445
 5248/12231 [===========>..................] - ETA: 55s - loss: 0.8564 - acc: 0.5450
 5376/12231 [============>.................] - ETA: 53s - loss: 0.8553 - acc: 0.5463
 5504/12231 [============>.................] - ETA: 52s - loss: 0.8548 - acc: 0.5456
 5632/12231 [============>.................] - ETA: 51s - loss: 0.8543 - acc: 0.5453
 5760/12231 [=============>................] - ETA: 49s - loss: 0.8545 - acc: 0.5441
 5888/12231 [=============>................] - ETA: 48s - loss: 0.8550 - acc: 0.5436
 6016/12231 [=============>................] - ETA: 47s - loss: 0.8543 - acc: 0.5442
 6144/12231 [==============>...............] - ETA: 46s - loss: 0.8539 - acc: 0.5448
 6272/12231 [==============>...............] - ETA: 45s - loss: 0.8541 - acc: 0.5451
 6400/12231 [==============>...............] - ETA: 43s - loss: 0.8534 - acc: 0.5447
 6528/12231 [===============>..............] - ETA: 42s - loss: 0.8532 - acc: 0.5434
 6656/12231 [===============>..............] - ETA: 41s - loss: 0.8525 - acc: 0.5439
 6784/12231 [===============>..............] - ETA: 40s - loss: 0.8519 - acc: 0.5442
 6912/12231 [===============>..............] - ETA: 39s - loss: 0.8519 - acc: 0.5425
 7040/12231 [================>.............] - ETA: 38s - loss: 0.8515 - acc: 0.5420
 7168/12231 [================>.............] - ETA: 36s - loss: 0.8514 - acc: 0.5399
 7296/12231 [================>.............] - ETA: 35s - loss: 0.8509 - acc: 0.5395
 7424/12231 [=================>............] - ETA: 34s - loss: 0.8505 - acc: 0.5403
 7552/12231 [=================>............] - ETA: 33s - loss: 0.8501 - acc: 0.5397
 7680/12231 [=================>............] - ETA: 32s - loss: 0.8499 - acc: 0.5395
 7808/12231 [==================>...........] - ETA: 31s - loss: 0.8491 - acc: 0.5405
 7936/12231 [==================>...........] - ETA: 30s - loss: 0.8483 - acc: 0.5415
 8064/12231 [==================>...........] - ETA: 29s - loss: 0.8480 - acc: 0.5414
 8192/12231 [===================>..........] - ETA: 28s - loss: 0.8478 - acc: 0.5406
 8320/12231 [===================>..........] - ETA: 27s - loss: 0.8473 - acc: 0.5397
 8448/12231 [===================>..........] - ETA: 26s - loss: 0.8470 - acc: 0.5397
 8576/12231 [====================>.........] - ETA: 25s - loss: 0.8463 - acc: 0.5409
 8704/12231 [====================>.........] - ETA: 24s - loss: 0.8460 - acc: 0.5408
 8832/12231 [====================>.........] - ETA: 23s - loss: 0.8453 - acc: 0.5410
 8960/12231 [====================>.........] - ETA: 22s - loss: 0.8445 - acc: 0.5421
 9088/12231 [=====================>........] - ETA: 21s - loss: 0.8442 - acc: 0.5429
 9216/12231 [=====================>........] - ETA: 20s - loss: 0.8428 - acc: 0.5449
 9344/12231 [=====================>........] - ETA: 19s - loss: 0.8426 - acc: 0.5453
 9472/12231 [======================>.......] - ETA: 18s - loss: 0.8426 - acc: 0.5453
 9600/12231 [======================>.......] - ETA: 17s - loss: 0.8422 - acc: 0.5454
 9728/12231 [======================>.......] - ETA: 16s - loss: 0.8416 - acc: 0.5461
 9856/12231 [=======================>......] - ETA: 16s - loss: 0.8408 - acc: 0.5477
 9984/12231 [=======================>......] - ETA: 15s - loss: 0.8402 - acc: 0.5484
10112/12231 [=======================>......] - ETA: 14s - loss: 0.8398 - acc: 0.5487
10240/12231 [========================>.....] - ETA: 13s - loss: 0.8390 - acc: 0.5494
10368/12231 [========================>.....] - ETA: 12s - loss: 0.8388 - acc: 0.5488
10496/12231 [========================>.....] - ETA: 11s - loss: 0.8379 - acc: 0.5501
10624/12231 [=========================>....] - ETA: 10s - loss: 0.8375 - acc: 0.5504
10752/12231 [=========================>....] - ETA: 9s - loss: 0.8367 - acc: 0.5514 
10880/12231 [=========================>....] - ETA: 8s - loss: 0.8364 - acc: 0.5521
11008/12231 [==========================>...] - ETA: 8s - loss: 0.8357 - acc: 0.5533
11136/12231 [==========================>...] - ETA: 7s - loss: 0.8356 - acc: 0.5532
11264/12231 [==========================>...] - ETA: 6s - loss: 0.8349 - acc: 0.5542
11392/12231 [==========================>...] - ETA: 5s - loss: 0.8344 - acc: 0.5549
11520/12231 [===========================>..] - ETA: 4s - loss: 0.8336 - acc: 0.5557
11648/12231 [===========================>..] - ETA: 3s - loss: 0.8328 - acc: 0.5564
11776/12231 [===========================>..] - ETA: 2s - loss: 0.8326 - acc: 0.5565
11904/12231 [============================>.] - ETA: 2s - loss: 0.8318 - acc: 0.5575
12032/12231 [============================>.] - ETA: 1s - loss: 0.8309 - acc: 0.5584
12160/12231 [============================>.] - ETA: 0s - loss: 0.8301 - acc: 0.5595
12231/12231 [==============================] - 80s 7ms/step - loss: 0.8296 - acc: 0.5603 - val_loss: 0.7618 - val_acc: 0.6137
Epoch 2/10

  128/12231 [..............................] - ETA: 58s - loss: 0.7522 - acc: 0.6406
  256/12231 [..............................] - ETA: 57s - loss: 0.7538 - acc: 0.6211
  384/12231 [..............................] - ETA: 56s - loss: 0.7712 - acc: 0.5964
  512/12231 [>.............................] - ETA: 56s - loss: 0.7685 - acc: 0.6094
  640/12231 [>.............................] - ETA: 56s - loss: 0.7710 - acc: 0.6047
  768/12231 [>.............................] - ETA: 55s - loss: 0.7787 - acc: 0.5990
  896/12231 [=>............................] - ETA: 55s - loss: 0.7767 - acc: 0.6038
 1024/12231 [=>............................] - ETA: 54s - loss: 0.7736 - acc: 0.6094
 1152/12231 [=>............................] - ETA: 53s - loss: 0.7693 - acc: 0.6128
 1280/12231 [==>...........................] - ETA: 53s - loss: 0.7650 - acc: 0.6188
 1408/12231 [==>...........................] - ETA: 52s - loss: 0.7626 - acc: 0.6200
 1536/12231 [==>...........................] - ETA: 52s - loss: 0.7603 - acc: 0.6217
 1664/12231 [===>..........................] - ETA: 52s - loss: 0.7589 - acc: 0.6256
 1792/12231 [===>..........................] - ETA: 51s - loss: 0.7579 - acc: 0.6267
 1920/12231 [===>..........................] - ETA: 51s - loss: 0.7584 - acc: 0.6266
 2048/12231 [====>.........................] - ETA: 50s - loss: 0.7594 - acc: 0.6250
 2176/12231 [====>.........................] - ETA: 50s - loss: 0.7567 - acc: 0.6314
 2304/12231 [====>.........................] - ETA: 49s - loss: 0.7564 - acc: 0.6306
 2432/12231 [====>.........................] - ETA: 48s - loss: 0.7552 - acc: 0.6320
 4096/12231 [=========>....................] - ETA: 25s - loss: 0.7472 - acc: 0.6475
 4224/12231 [=========>....................] - ETA: 27s - loss: 0.7469 - acc: 0.6475
 4352/12231 [=========>....................] - ETA: 27s - loss: 0.7476 - acc: 0.6466
 4480/12231 [=========>....................] - ETA: 26s - loss: 0.7466 - acc: 0.6487
 4608/12231 [==========>...................] - ETA: 26s - loss: 0.7451 - acc: 0.6493
 4736/12231 [==========>...................] - ETA: 26s - loss: 0.7451 - acc: 0.6493
 4864/12231 [==========>...................] - ETA: 26s - loss: 0.7443 - acc: 0.6493
 4992/12231 [===========>..................] - ETA: 26s - loss: 0.7435 - acc: 0.6500
 5120/12231 [===========>..................] - ETA: 26s - loss: 0.7422 - acc: 0.6510
 5248/12231 [===========>..................] - ETA: 25s - loss: 0.7430 - acc: 0.6498
 5376/12231 [============>.................] - ETA: 25s - loss: 0.7428 - acc: 0.6494
 5504/12231 [============>.................] - ETA: 25s - loss: 0.7422 - acc: 0.6493
 5632/12231 [============>.................] - ETA: 24s - loss: 0.7402 - acc: 0.6509
 5760/12231 [=============>................] - ETA: 24s - loss: 0.7400 - acc: 0.6503
 5888/12231 [=============>................] - ETA: 24s - loss: 0.7402 - acc: 0.6501
 6016/12231 [=============>................] - ETA: 23s - loss: 0.7386 - acc: 0.6519
 6144/12231 [==============>...............] - ETA: 23s - loss: 0.7365 - acc: 0.6536
 6272/12231 [==============>...............] - ETA: 23s - loss: 0.7354 - acc: 0.6547
 6400/12231 [==============>...............] - ETA: 22s - loss: 0.7352 - acc: 0.6545
 6528/12231 [===============>..............] - ETA: 22s - loss: 0.7340 - acc: 0.6556
 6656/12231 [===============>..............] - ETA: 22s - loss: 0.7334 - acc: 0.6561
 6784/12231 [===============>..............] - ETA: 21s - loss: 0.7332 - acc: 0.6564
 6912/12231 [===============>..............] - ETA: 21s - loss: 0.7320 - acc: 0.6562
 7040/12231 [================>.............] - ETA: 20s - loss: 0.7305 - acc: 0.6584
 7168/12231 [================>.............] - ETA: 20s - loss: 0.7298 - acc: 0.6588
 7296/12231 [================>.............] - ETA: 20s - loss: 0.7286 - acc: 0.6594
 7424/12231 [=================>............] - ETA: 19s - loss: 0.7277 - acc: 0.6600
 7552/12231 [=================>............] - ETA: 19s - loss: 0.7267 - acc: 0.6615
 7680/12231 [=================>............] - ETA: 18s - loss: 0.7249 - acc: 0.6634
 7808/12231 [==================>...........] - ETA: 18s - loss: 0.7238 - acc: 0.6632
 7936/12231 [==================>...........] - ETA: 17s - loss: 0.7230 - acc: 0.6639
 8064/12231 [==================>...........] - ETA: 17s - loss: 0.7216 - acc: 0.6658
 8192/12231 [===================>..........] - ETA: 16s - loss: 0.7216 - acc: 0.6659
 8320/12231 [===================>..........] - ETA: 16s - loss: 0.7213 - acc: 0.6657
 8448/12231 [===================>..........] - ETA: 15s - loss: 0.7201 - acc: 0.6665
 8576/12231 [====================>.........] - ETA: 15s - loss: 0.7195 - acc: 0.6664
 8704/12231 [====================>.........] - ETA: 14s - loss: 0.7185 - acc: 0.6676
 8832/12231 [====================>.........] - ETA: 14s - loss: 0.7176 - acc: 0.6680
 8960/12231 [====================>.........] - ETA: 13s - loss: 0.7164 - acc: 0.6691
 9088/12231 [=====================>........] - ETA: 13s - loss: 0.7162 - acc: 0.6692
 9216/12231 [=====================>........] - ETA: 12s - loss: 0.7153 - acc: 0.6696
 9344/12231 [=====================>........] - ETA: 12s - loss: 0.7141 - acc: 0.6705
 9472/12231 [======================>.......] - ETA: 11s - loss: 0.7140 - acc: 0.6704
 9600/12231 [======================>.......] - ETA: 11s - loss: 0.7135 - acc: 0.6714
 9728/12231 [======================>.......] - ETA: 10s - loss: 0.7123 - acc: 0.6724
 9856/12231 [=======================>......] - ETA: 10s - loss: 0.7118 - acc: 0.6734
 9984/12231 [=======================>......] - ETA: 9s - loss: 0.7108 - acc: 0.6742 
10112/12231 [=======================>......] - ETA: 9s - loss: 0.7106 - acc: 0.6741
10240/12231 [========================>.....] - ETA: 8s - loss: 0.7105 - acc: 0.6738
10368/12231 [========================>.....] - ETA: 8s - loss: 0.7099 - acc: 0.6742
10496/12231 [========================>.....] - ETA: 7s - loss: 0.7095 - acc: 0.6744
10624/12231 [=========================>....] - ETA: 6s - loss: 0.7088 - acc: 0.6750
10752/12231 [=========================>....] - ETA: 6s - loss: 0.7078 - acc: 0.6759
10880/12231 [=========================>....] - ETA: 5s - loss: 0.7079 - acc: 0.6757
11008/12231 [==========================>...] - ETA: 5s - loss: 0.7063 - acc: 0.6770
11136/12231 [==========================>...] - ETA: 4s - loss: 0.7058 - acc: 0.6775
11264/12231 [==========================>...] - ETA: 4s - loss: 0.7042 - acc: 0.6785
11392/12231 [==========================>...] - ETA: 3s - loss: 0.7037 - acc: 0.6792
11520/12231 [===========================>..] - ETA: 3s - loss: 0.7027 - acc: 0.6802
11648/12231 [===========================>..] - ETA: 2s - loss: 0.7017 - acc: 0.6808
11776/12231 [===========================>..] - ETA: 1s - loss: 0.7004 - acc: 0.6818
11904/12231 [============================>.] - ETA: 1s - loss: 0.6998 - acc: 0.6821
12032/12231 [============================>.] - ETA: 0s - loss: 0.6986 - acc: 0.6828
12160/12231 [============================>.] - ETA: 0s - loss: 0.6977 - acc: 0.6832
12231/12231 [==============================] - 57s 5ms/step - loss: 0.6972 - acc: 0.6836 - val_loss: 0.6100 - val_acc: 0.7498
Epoch 3/10

  128/12231 [..............................] - ETA: 1:04 - loss: 0.5972 - acc: 0.7500
  256/12231 [..............................] - ETA: 1:04 - loss: 0.5706 - acc: 0.7891
  384/12231 [..............................] - ETA: 1:03 - loss: 0.5793 - acc: 0.7734
  512/12231 [>.............................] - ETA: 1:02 - loss: 0.5570 - acc: 0.7852
  640/12231 [>.............................] - ETA: 1:04 - loss: 0.5562 - acc: 0.7828
  768/12231 [>.............................] - ETA: 1:10 - loss: 0.5528 - acc: 0.7839
  896/12231 [=>............................] - ETA: 1:11 - loss: 0.5476 - acc: 0.7857
 1024/12231 [=>............................] - ETA: 1:12 - loss: 0.5724 - acc: 0.7725
 1152/12231 [=>............................] - ETA: 1:10 - loss: 0.5661 - acc: 0.7752
 1280/12231 [==>...........................] - ETA: 1:08 - loss: 0.5684 - acc: 0.7773
 1408/12231 [==>...........................] - ETA: 1:06 - loss: 0.5811 - acc: 0.7685
 1536/12231 [==>...........................] - ETA: 1:04 - loss: 0.5755 - acc: 0.7721
 1664/12231 [===>..........................] - ETA: 1:03 - loss: 0.5737 - acc: 0.7716
 1792/12231 [===>..........................] - ETA: 1:06 - loss: 0.5714 - acc: 0.7751
 1920/12231 [===>..........................] - ETA: 1:05 - loss: 0.5726 - acc: 0.7745
 2048/12231 [====>.........................] - ETA: 1:05 - loss: 0.5733 - acc: 0.7734
 2176/12231 [====>.........................] - ETA: 1:03 - loss: 0.5709 - acc: 0.7744
 2304/12231 [====>.........................] - ETA: 1:02 - loss: 0.5698 - acc: 0.7747
 2432/12231 [====>.........................] - ETA: 1:01 - loss: 0.5635 - acc: 0.7796
 2560/12231 [=====>........................] - ETA: 59s - loss: 0.5575 - acc: 0.7820 
 2688/12231 [=====>........................] - ETA: 58s - loss: 0.5638 - acc: 0.7790
 2816/12231 [=====>........................] - ETA: 57s - loss: 0.5655 - acc: 0.7795
 2944/12231 [======>.......................] - ETA: 56s - loss: 0.5637 - acc: 0.7812
 3072/12231 [======>.......................] - ETA: 55s - loss: 0.5623 - acc: 0.7826
 3200/12231 [======>.......................] - ETA: 54s - loss: 0.5621 - acc: 0.7806
 3328/12231 [=======>......................] - ETA: 53s - loss: 0.5635 - acc: 0.7782
 3456/12231 [=======>......................] - ETA: 52s - loss: 0.5609 - acc: 0.7804
 3584/12231 [=======>......................] - ETA: 51s - loss: 0.5606 - acc: 0.7801
 3712/12231 [========>.....................] - ETA: 50s - loss: 0.5604 - acc: 0.7791
 3840/12231 [========>.....................] - ETA: 49s - loss: 0.5568 - acc: 0.7823
 3968/12231 [========>.....................] - ETA: 48s - loss: 0.5547 - acc: 0.7848
 4096/12231 [=========>....................] - ETA: 47s - loss: 0.5550 - acc: 0.7847
 4224/12231 [=========>....................] - ETA: 46s - loss: 0.5528 - acc: 0.7860
 4352/12231 [=========>....................] - ETA: 45s - loss: 0.5522 - acc: 0.7861
 4480/12231 [=========>....................] - ETA: 44s - loss: 0.5539 - acc: 0.7866
 4608/12231 [==========>...................] - ETA: 44s - loss: 0.5501 - acc: 0.7882
 4736/12231 [==========>...................] - ETA: 43s - loss: 0.5503 - acc: 0.7872
 4864/12231 [==========>...................] - ETA: 42s - loss: 0.5503 - acc: 0.7862
 4992/12231 [===========>..................] - ETA: 41s - loss: 0.5516 - acc: 0.7855
 5120/12231 [===========>..................] - ETA: 40s - loss: 0.5515 - acc: 0.7863
 5248/12231 [===========>..................] - ETA: 40s - loss: 0.5512 - acc: 0.7864
 5376/12231 [============>.................] - ETA: 39s - loss: 0.5526 - acc: 0.7846
 5504/12231 [============>.................] - ETA: 38s - loss: 0.5519 - acc: 0.7851
 5632/12231 [============>.................] - ETA: 37s - loss: 0.5524 - acc: 0.7855
 5760/12231 [=============>................] - ETA: 36s - loss: 0.5522 - acc: 0.7856
 5888/12231 [=============>................] - ETA: 36s - loss: 0.5513 - acc: 0.7857
 6016/12231 [=============>................] - ETA: 35s - loss: 0.5510 - acc: 0.7857
 6144/12231 [==============>...............] - ETA: 34s - loss: 0.5510 - acc: 0.7860
 6272/12231 [==============>...............] - ETA: 33s - loss: 0.5491 - acc: 0.7867
 6400/12231 [==============>...............] - ETA: 33s - loss: 0.5486 - acc: 0.7872
 6528/12231 [===============>..............] - ETA: 32s - loss: 0.5479 - acc: 0.7871
 6656/12231 [===============>..............] - ETA: 31s - loss: 0.5479 - acc: 0.7864
 6784/12231 [===============>..............] - ETA: 31s - loss: 0.5483 - acc: 0.7858
 6912/12231 [===============>..............] - ETA: 30s - loss: 0.5454 - acc: 0.7876
 7040/12231 [================>.............] - ETA: 29s - loss: 0.5441 - acc: 0.7881
 7168/12231 [================>.............] - ETA: 29s - loss: 0.5439 - acc: 0.7885
 7296/12231 [================>.............] - ETA: 28s - loss: 0.5427 - acc: 0.7888
 7424/12231 [=================>............] - ETA: 27s - loss: 0.5428 - acc: 0.7885
 7552/12231 [=================>............] - ETA: 26s - loss: 0.5426 - acc: 0.7889
 7680/12231 [=================>............] - ETA: 25s - loss: 0.5421 - acc: 0.7884
 7808/12231 [==================>...........] - ETA: 25s - loss: 0.5420 - acc: 0.7884
 7936/12231 [==================>...........] - ETA: 24s - loss: 0.5427 - acc: 0.7878
 8064/12231 [==================>...........] - ETA: 23s - loss: 0.5430 - acc: 0.7871
 8192/12231 [===================>..........] - ETA: 22s - loss: 0.5433 - acc: 0.7869
 8320/12231 [===================>..........] - ETA: 22s - loss: 0.5424 - acc: 0.7876
 8448/12231 [===================>..........] - ETA: 21s - loss: 0.5416 - acc: 0.7879
 8576/12231 [====================>.........] - ETA: 20s - loss: 0.5404 - acc: 0.7886
 8704/12231 [====================>.........] - ETA: 19s - loss: 0.5391 - acc: 0.7896
 8832/12231 [====================>.........] - ETA: 19s - loss: 0.5394 - acc: 0.7896
 8960/12231 [====================>.........] - ETA: 18s - loss: 0.5382 - acc: 0.7907
 9088/12231 [=====================>........] - ETA: 17s - loss: 0.5383 - acc: 0.7903
 9216/12231 [=====================>........] - ETA: 16s - loss: 0.5386 - acc: 0.7901
 9344/12231 [=====================>........] - ETA: 16s - loss: 0.5379 - acc: 0.7906
 9472/12231 [======================>.......] - ETA: 15s - loss: 0.5369 - acc: 0.7914
 9600/12231 [======================>.......] - ETA: 14s - loss: 0.5359 - acc: 0.7919
 9728/12231 [======================>.......] - ETA: 13s - loss: 0.5361 - acc: 0.7919
 9856/12231 [=======================>......] - ETA: 13s - loss: 0.5367 - acc: 0.7913
 9984/12231 [=======================>......] - ETA: 12s - loss: 0.5354 - acc: 0.7923
10112/12231 [=======================>......] - ETA: 11s - loss: 0.5346 - acc: 0.7929
10240/12231 [========================>.....] - ETA: 11s - loss: 0.5347 - acc: 0.7926
10368/12231 [========================>.....] - ETA: 10s - loss: 0.5336 - acc: 0.7932
10496/12231 [========================>.....] - ETA: 9s - loss: 0.5328 - acc: 0.7939 
10624/12231 [=========================>....] - ETA: 8s - loss: 0.5321 - acc: 0.7941
10752/12231 [=========================>....] - ETA: 8s - loss: 0.5318 - acc: 0.7940
10880/12231 [=========================>....] - ETA: 7s - loss: 0.5301 - acc: 0.7949
11008/12231 [==========================>...] - ETA: 6s - loss: 0.5287 - acc: 0.7956
11136/12231 [==========================>...] - ETA: 6s - loss: 0.5272 - acc: 0.7967
11264/12231 [==========================>...] - ETA: 5s - loss: 0.5275 - acc: 0.7967
11392/12231 [==========================>...] - ETA: 4s - loss: 0.5279 - acc: 0.7968
11520/12231 [===========================>..] - ETA: 3s - loss: 0.5274 - acc: 0.7971
11648/12231 [===========================>..] - ETA: 3s - loss: 0.5272 - acc: 0.7976
11776/12231 [===========================>..] - ETA: 2s - loss: 0.5264 - acc: 0.7979
11904/12231 [============================>.] - ETA: 1s - loss: 0.5268 - acc: 0.7979
12032/12231 [============================>.] - ETA: 1s - loss: 0.5262 - acc: 0.7979
12160/12231 [============================>.] - ETA: 0s - loss: 0.5260 - acc: 0.7977
12231/12231 [==============================] - 69s 6ms/step - loss: 0.5257 - acc: 0.7980 - val_loss: 0.5258 - val_acc: 0.7962
Epoch 4/10

  128/12231 [..............................] - ETA: 1:03 - loss: 0.4547 - acc: 0.8516
  256/12231 [..............................] - ETA: 1:01 - loss: 0.4681 - acc: 0.8438
  384/12231 [..............................] - ETA: 1:00 - loss: 0.4601 - acc: 0.8385
  512/12231 [>.............................] - ETA: 59s - loss: 0.4619 - acc: 0.8340 
  640/12231 [>.............................] - ETA: 58s - loss: 0.4657 - acc: 0.8234
  768/12231 [>.............................] - ETA: 57s - loss: 0.4585 - acc: 0.8281
  896/12231 [=>............................] - ETA: 56s - loss: 0.4515 - acc: 0.8292
 1024/12231 [=>............................] - ETA: 56s - loss: 0.4422 - acc: 0.8340
 1152/12231 [=>............................] - ETA: 55s - loss: 0.4471 - acc: 0.8307
 1280/12231 [==>...........................] - ETA: 55s - loss: 0.4486 - acc: 0.8297
 1408/12231 [==>...........................] - ETA: 54s - loss: 0.4536 - acc: 0.8274
 1536/12231 [==>...........................] - ETA: 53s - loss: 0.4551 - acc: 0.8275
 1664/12231 [===>..........................] - ETA: 53s - loss: 0.4522 - acc: 0.8311
 1792/12231 [===>..........................] - ETA: 52s - loss: 0.4471 - acc: 0.8320
 1920/12231 [===>..........................] - ETA: 51s - loss: 0.4470 - acc: 0.8333
 2048/12231 [====>.........................] - ETA: 51s - loss: 0.4444 - acc: 0.8354
 2176/12231 [====>.........................] - ETA: 50s - loss: 0.4458 - acc: 0.8341
 2304/12231 [====>.........................] - ETA: 49s - loss: 0.4436 - acc: 0.8372
 2432/12231 [====>.........................] - ETA: 49s - loss: 0.4407 - acc: 0.8396
 2560/12231 [=====>........................] - ETA: 48s - loss: 0.4427 - acc: 0.8383
 2688/12231 [=====>........................] - ETA: 47s - loss: 0.4396 - acc: 0.8415
 2816/12231 [=====>........................] - ETA: 47s - loss: 0.4393 - acc: 0.8430
 2944/12231 [======>.......................] - ETA: 46s - loss: 0.4396 - acc: 0.8421
 3072/12231 [======>.......................] - ETA: 45s - loss: 0.4352 - acc: 0.8454
 3200/12231 [======>.......................] - ETA: 45s - loss: 0.4376 - acc: 0.8434
 3328/12231 [=======>......................] - ETA: 44s - loss: 0.4381 - acc: 0.8416
 3456/12231 [=======>......................] - ETA: 43s - loss: 0.4377 - acc: 0.8426
 3584/12231 [=======>......................] - ETA: 43s - loss: 0.4358 - acc: 0.8440
 3712/12231 [========>.....................] - ETA: 42s - loss: 0.4341 - acc: 0.8443
 3840/12231 [========>.....................] - ETA: 41s - loss: 0.4319 - acc: 0.8458
 3968/12231 [========>.....................] - ETA: 41s - loss: 0.4322 - acc: 0.8445
 4096/12231 [=========>....................] - ETA: 40s - loss: 0.4303 - acc: 0.8459
 4224/12231 [=========>....................] - ETA: 40s - loss: 0.4315 - acc: 0.8456
 4352/12231 [=========>....................] - ETA: 39s - loss: 0.4310 - acc: 0.8454
 4480/12231 [=========>....................] - ETA: 38s - loss: 0.4302 - acc: 0.8458
 4608/12231 [==========>...................] - ETA: 38s - loss: 0.4290 - acc: 0.8459
 4736/12231 [==========>...................] - ETA: 37s - loss: 0.4275 - acc: 0.8471
 4864/12231 [==========>...................] - ETA: 36s - loss: 0.4273 - acc: 0.8475
 4992/12231 [===========>..................] - ETA: 36s - loss: 0.4269 - acc: 0.8480
 5120/12231 [===========>..................] - ETA: 35s - loss: 0.4254 - acc: 0.8484
 5248/12231 [===========>..................] - ETA: 34s - loss: 0.4237 - acc: 0.8478
 5376/12231 [============>.................] - ETA: 34s - loss: 0.4220 - acc: 0.8482
 5504/12231 [============>.................] - ETA: 33s - loss: 0.4197 - acc: 0.8494
 5632/12231 [============>.................] - ETA: 32s - loss: 0.4213 - acc: 0.8487
 5760/12231 [=============>................] - ETA: 32s - loss: 0.4224 - acc: 0.8479
 5888/12231 [=============>................] - ETA: 31s - loss: 0.4229 - acc: 0.8477
 6016/12231 [=============>................] - ETA: 31s - loss: 0.4225 - acc: 0.8479
 6144/12231 [==============>...............] - ETA: 30s - loss: 0.4221 - acc: 0.8480
 6272/12231 [==============>...............] - ETA: 29s - loss: 0.4234 - acc: 0.8471
 6400/12231 [==============>...............] - ETA: 29s - loss: 0.4223 - acc: 0.8480
 6528/12231 [===============>..............] - ETA: 28s - loss: 0.4218 - acc: 0.8488
 6656/12231 [===============>..............] - ETA: 27s - loss: 0.4221 - acc: 0.8489
 6784/12231 [===============>..............] - ETA: 27s - loss: 0.4213 - acc: 0.8498
 6912/12231 [===============>..............] - ETA: 26s - loss: 0.4204 - acc: 0.8500
 7040/12231 [================>.............] - ETA: 25s - loss: 0.4205 - acc: 0.8494
 7168/12231 [================>.............] - ETA: 25s - loss: 0.4200 - acc: 0.8496
 7296/12231 [================>.............] - ETA: 24s - loss: 0.4195 - acc: 0.8501
 7424/12231 [=================>............] - ETA: 24s - loss: 0.4210 - acc: 0.8498
 7552/12231 [=================>............] - ETA: 23s - loss: 0.4205 - acc: 0.8500
 7680/12231 [=================>............] - ETA: 22s - loss: 0.4210 - acc: 0.8491
 7808/12231 [==================>...........] - ETA: 22s - loss: 0.4211 - acc: 0.8487
 7936/12231 [==================>...........] - ETA: 21s - loss: 0.4216 - acc: 0.8487
 8064/12231 [==================>...........] - ETA: 20s - loss: 0.4217 - acc: 0.8486
 8192/12231 [===================>..........] - ETA: 20s - loss: 0.4207 - acc: 0.8495
 8320/12231 [===================>..........] - ETA: 19s - loss: 0.4191 - acc: 0.8504
 8448/12231 [===================>..........] - ETA: 18s - loss: 0.4183 - acc: 0.8511
 8576/12231 [====================>.........] - ETA: 18s - loss: 0.4192 - acc: 0.8504
 8704/12231 [====================>.........] - ETA: 17s - loss: 0.4185 - acc: 0.8505
 8832/12231 [====================>.........] - ETA: 16s - loss: 0.4182 - acc: 0.8508
 8960/12231 [====================>.........] - ETA: 16s - loss: 0.4177 - acc: 0.8504
 9088/12231 [=====================>........] - ETA: 15s - loss: 0.4173 - acc: 0.8505
 9216/12231 [=====================>........] - ETA: 15s - loss: 0.4180 - acc: 0.8499
 9344/12231 [=====================>........] - ETA: 14s - loss: 0.4170 - acc: 0.8503
 9472/12231 [======================>.......] - ETA: 13s - loss: 0.4167 - acc: 0.8503
 9600/12231 [======================>.......] - ETA: 13s - loss: 0.4163 - acc: 0.8506
 9728/12231 [======================>.......] - ETA: 12s - loss: 0.4154 - acc: 0.8509
 9856/12231 [=======================>......] - ETA: 11s - loss: 0.4144 - acc: 0.8513
 9984/12231 [=======================>......] - ETA: 11s - loss: 0.4138 - acc: 0.8514
10112/12231 [=======================>......] - ETA: 10s - loss: 0.4136 - acc: 0.8517
10240/12231 [========================>.....] - ETA: 9s - loss: 0.4140 - acc: 0.8513 
10368/12231 [========================>.....] - ETA: 9s - loss: 0.4122 - acc: 0.8519
10496/12231 [========================>.....] - ETA: 8s - loss: 0.4108 - acc: 0.8523
10624/12231 [=========================>....] - ETA: 8s - loss: 0.4103 - acc: 0.8524
10752/12231 [=========================>....] - ETA: 7s - loss: 0.4099 - acc: 0.8525
10880/12231 [=========================>....] - ETA: 6s - loss: 0.4087 - acc: 0.8531
11008/12231 [==========================>...] - ETA: 6s - loss: 0.4088 - acc: 0.8531
11136/12231 [==========================>...] - ETA: 5s - loss: 0.4082 - acc: 0.8531
11264/12231 [==========================>...] - ETA: 4s - loss: 0.4076 - acc: 0.8534
11392/12231 [==========================>...] - ETA: 4s - loss: 0.4073 - acc: 0.8539
11520/12231 [===========================>..] - ETA: 3s - loss: 0.4076 - acc: 0.8536
11648/12231 [===========================>..] - ETA: 3s - loss: 0.4070 - acc: 0.8537
11776/12231 [===========================>..] - ETA: 2s - loss: 0.4065 - acc: 0.8537
11904/12231 [============================>.] - ETA: 1s - loss: 0.4047 - acc: 0.8546
12032/12231 [============================>.] - ETA: 1s - loss: 0.4036 - acc: 0.8553
12160/12231 [============================>.] - ETA: 0s - loss: 0.4035 - acc: 0.8551
12231/12231 [==============================] - 66s 5ms/step - loss: 0.4031 - acc: 0.8551 - val_loss: 0.4566 - val_acc: 0.8227
Epoch 5/10

  128/12231 [..............................] - ETA: 1:01 - loss: 0.2763 - acc: 0.9297
  256/12231 [..............................] - ETA: 1:00 - loss: 0.2734 - acc: 0.9297
  384/12231 [..............................] - ETA: 59s - loss: 0.2949 - acc: 0.9193 
  512/12231 [>.............................] - ETA: 58s - loss: 0.2827 - acc: 0.9199
  640/12231 [>.............................] - ETA: 57s - loss: 0.2677 - acc: 0.9203
  768/12231 [>.............................] - ETA: 57s - loss: 0.2759 - acc: 0.9141
  896/12231 [=>............................] - ETA: 56s - loss: 0.2771 - acc: 0.9163
 1024/12231 [=>............................] - ETA: 55s - loss: 0.2840 - acc: 0.9141
 1152/12231 [=>............................] - ETA: 55s - loss: 0.2973 - acc: 0.9106
 1280/12231 [==>...........................] - ETA: 54s - loss: 0.2960 - acc: 0.9070
 1408/12231 [==>...........................] - ETA: 54s - loss: 0.2929 - acc: 0.9077
 1536/12231 [==>...........................] - ETA: 53s - loss: 0.3074 - acc: 0.9004
 1664/12231 [===>..........................] - ETA: 52s - loss: 0.3145 - acc: 0.8948
 1792/12231 [===>..........................] - ETA: 52s - loss: 0.3151 - acc: 0.8951
 1920/12231 [===>..........................] - ETA: 51s - loss: 0.3170 - acc: 0.8938
 2048/12231 [====>.........................] - ETA: 51s - loss: 0.3209 - acc: 0.8911
 2176/12231 [====>.........................] - ETA: 50s - loss: 0.3200 - acc: 0.8911
 2304/12231 [====>.........................] - ETA: 49s - loss: 0.3200 - acc: 0.8924
 2432/12231 [====>.........................] - ETA: 49s - loss: 0.3265 - acc: 0.8890
 2560/12231 [=====>........................] - ETA: 48s - loss: 0.3300 - acc: 0.8871
 2688/12231 [=====>........................] - ETA: 48s - loss: 0.3312 - acc: 0.8869
 2816/12231 [=====>........................] - ETA: 47s - loss: 0.3273 - acc: 0.8892
 2944/12231 [======>.......................] - ETA: 46s - loss: 0.3315 - acc: 0.8872
 3072/12231 [======>.......................] - ETA: 46s - loss: 0.3298 - acc: 0.8877
 3200/12231 [======>.......................] - ETA: 45s - loss: 0.3269 - acc: 0.8888
 3328/12231 [=======>......................] - ETA: 44s - loss: 0.3293 - acc: 0.8879
 3456/12231 [=======>......................] - ETA: 44s - loss: 0.3296 - acc: 0.8874
 3584/12231 [=======>......................] - ETA: 43s - loss: 0.3277 - acc: 0.8884
 3712/12231 [========>.....................] - ETA: 42s - loss: 0.3294 - acc: 0.8863
 3840/12231 [========>.....................] - ETA: 42s - loss: 0.3302 - acc: 0.8854
 3968/12231 [========>.....................] - ETA: 41s - loss: 0.3303 - acc: 0.8856
 4096/12231 [=========>....................] - ETA: 41s - loss: 0.3297 - acc: 0.8857
 4224/12231 [=========>....................] - ETA: 40s - loss: 0.3279 - acc: 0.8866
 4352/12231 [=========>....................] - ETA: 39s - loss: 0.3276 - acc: 0.8863
 4480/12231 [=========>....................] - ETA: 39s - loss: 0.3250 - acc: 0.8873
 4608/12231 [==========>...................] - ETA: 38s - loss: 0.3230 - acc: 0.8882
 4736/12231 [==========>...................] - ETA: 37s - loss: 0.3235 - acc: 0.8883
 4864/12231 [==========>...................] - ETA: 37s - loss: 0.3225 - acc: 0.8888
 4992/12231 [===========>..................] - ETA: 36s - loss: 0.3247 - acc: 0.8876
 5120/12231 [===========>..................] - ETA: 35s - loss: 0.3249 - acc: 0.8871
 5248/12231 [===========>..................] - ETA: 35s - loss: 0.3240 - acc: 0.8870
 5376/12231 [============>.................] - ETA: 34s - loss: 0.3265 - acc: 0.8860
 5504/12231 [============>.................] - ETA: 33s - loss: 0.3270 - acc: 0.8861
 5632/12231 [============>.................] - ETA: 33s - loss: 0.3295 - acc: 0.8853
 5760/12231 [=============>................] - ETA: 32s - loss: 0.3307 - acc: 0.8852
 5888/12231 [=============>................] - ETA: 31s - loss: 0.3311 - acc: 0.8847
 6016/12231 [=============>................] - ETA: 31s - loss: 0.3322 - acc: 0.8833
 6144/12231 [==============>...............] - ETA: 30s - loss: 0.3327 - acc: 0.8833
 6272/12231 [==============>...............] - ETA: 30s - loss: 0.3331 - acc: 0.8828
 6400/12231 [==============>...............] - ETA: 29s - loss: 0.3318 - acc: 0.8841
 6528/12231 [===============>..............] - ETA: 28s - loss: 0.3303 - acc: 0.8848
 6656/12231 [===============>..............] - ETA: 28s - loss: 0.3292 - acc: 0.8846
 6784/12231 [===============>..............] - ETA: 27s - loss: 0.3297 - acc: 0.8844
 6912/12231 [===============>..............] - ETA: 26s - loss: 0.3297 - acc: 0.8845
 7040/12231 [================>.............] - ETA: 26s - loss: 0.3294 - acc: 0.8848
 7168/12231 [================>.............] - ETA: 25s - loss: 0.3293 - acc: 0.8846
 7296/12231 [================>.............] - ETA: 24s - loss: 0.3296 - acc: 0.8850
 7424/12231 [=================>............] - ETA: 24s - loss: 0.3289 - acc: 0.8856
 7552/12231 [=================>............] - ETA: 23s - loss: 0.3278 - acc: 0.8860
 7680/12231 [=================>............] - ETA: 22s - loss: 0.3287 - acc: 0.8861
 7808/12231 [==================>...........] - ETA: 22s - loss: 0.3294 - acc: 0.8858
 7936/12231 [==================>...........] - ETA: 21s - loss: 0.3295 - acc: 0.8858
 8064/12231 [==================>...........] - ETA: 20s - loss: 0.3295 - acc: 0.8859
 8192/12231 [===================>..........] - ETA: 20s - loss: 0.3288 - acc: 0.8864
 8320/12231 [===================>..........] - ETA: 19s - loss: 0.3290 - acc: 0.8864
 8448/12231 [===================>..........] - ETA: 19s - loss: 0.3299 - acc: 0.8858
 8576/12231 [====================>.........] - ETA: 18s - loss: 0.3297 - acc: 0.8855
 8704/12231 [====================>.........] - ETA: 17s - loss: 0.3307 - acc: 0.8852
 8832/12231 [====================>.........] - ETA: 17s - loss: 0.3306 - acc: 0.8858
 8960/12231 [====================>.........] - ETA: 16s - loss: 0.3302 - acc: 0.8862
 9088/12231 [=====================>........] - ETA: 15s - loss: 0.3304 - acc: 0.8858
 9216/12231 [=====================>........] - ETA: 15s - loss: 0.3296 - acc: 0.8863
 9344/12231 [=====================>........] - ETA: 14s - loss: 0.3302 - acc: 0.8861
 9472/12231 [======================>.......] - ETA: 14s - loss: 0.3296 - acc: 0.8865
 9600/12231 [======================>.......] - ETA: 13s - loss: 0.3291 - acc: 0.8871
 9728/12231 [======================>.......] - ETA: 12s - loss: 0.3290 - acc: 0.8869
 9856/12231 [=======================>......] - ETA: 12s - loss: 0.3304 - acc: 0.8862
 9984/12231 [=======================>......] - ETA: 11s - loss: 0.3294 - acc: 0.8865
10112/12231 [=======================>......] - ETA: 11s - loss: 0.3298 - acc: 0.8867
10240/12231 [========================>.....] - ETA: 10s - loss: 0.3289 - acc: 0.8871
10368/12231 [========================>.....] - ETA: 9s - loss: 0.3297 - acc: 0.8871 
10496/12231 [========================>.....] - ETA: 9s - loss: 0.3287 - acc: 0.8870
10624/12231 [=========================>....] - ETA: 8s - loss: 0.3296 - acc: 0.8868
10752/12231 [=========================>....] - ETA: 7s - loss: 0.3290 - acc: 0.8869
10880/12231 [=========================>....] - ETA: 7s - loss: 0.3286 - acc: 0.8869
11008/12231 [==========================>...] - ETA: 6s - loss: 0.3280 - acc: 0.8874
11136/12231 [==========================>...] - ETA: 5s - loss: 0.3261 - acc: 0.8883
11264/12231 [==========================>...] - ETA: 5s - loss: 0.3257 - acc: 0.8884
11392/12231 [==========================>...] - ETA: 4s - loss: 0.3251 - acc: 0.8883
11520/12231 [===========================>..] - ETA: 3s - loss: 0.3246 - acc: 0.8885
11648/12231 [===========================>..] - ETA: 3s - loss: 0.3245 - acc: 0.8881
11776/12231 [===========================>..] - ETA: 2s - loss: 0.3244 - acc: 0.8879
11904/12231 [============================>.] - ETA: 1s - loss: 0.3240 - acc: 0.8878
12032/12231 [============================>.] - ETA: 1s - loss: 0.3241 - acc: 0.8878
12160/12231 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.8877
12231/12231 [==============================] - 69s 6ms/step - loss: 0.3247 - acc: 0.8879 - val_loss: 0.4229 - val_acc: 0.8425
Epoch 6/10

  128/12231 [..............................] - ETA: 1:20 - loss: 0.3039 - acc: 0.8906
  256/12231 [..............................] - ETA: 1:20 - loss: 0.2674 - acc: 0.9023
  384/12231 [..............................] - ETA: 1:16 - loss: 0.2570 - acc: 0.9115
  512/12231 [>.............................] - ETA: 1:15 - loss: 0.2448 - acc: 0.9180
  640/12231 [>.............................] - ETA: 1:13 - loss: 0.2566 - acc: 0.9156
  768/12231 [>.............................] - ETA: 1:11 - loss: 0.2510 - acc: 0.9180
  896/12231 [=>............................] - ETA: 1:10 - loss: 0.2456 - acc: 0.9230
 1024/12231 [=>............................] - ETA: 1:09 - loss: 0.2451 - acc: 0.9229
 1152/12231 [=>............................] - ETA: 1:07 - loss: 0.2472 - acc: 0.9227
 1280/12231 [==>...........................] - ETA: 1:06 - loss: 0.2434 - acc: 0.9227
 1408/12231 [==>...........................] - ETA: 1:05 - loss: 0.2483 - acc: 0.9219
 1536/12231 [==>...........................] - ETA: 1:03 - loss: 0.2505 - acc: 0.9219
 1664/12231 [===>..........................] - ETA: 1:02 - loss: 0.2461 - acc: 0.9207
 1792/12231 [===>..........................] - ETA: 1:01 - loss: 0.2439 - acc: 0.9213
 1920/12231 [===>..........................] - ETA: 1:02 - loss: 0.2416 - acc: 0.9219
 2048/12231 [====>.........................] - ETA: 1:02 - loss: 0.2438 - acc: 0.9219
 2176/12231 [====>.........................] - ETA: 1:01 - loss: 0.2450 - acc: 0.9205
 2304/12231 [====>.........................] - ETA: 1:00 - loss: 0.2427 - acc: 0.9214
 2432/12231 [====>.........................] - ETA: 59s - loss: 0.2446 - acc: 0.9190 
 2560/12231 [=====>........................] - ETA: 58s - loss: 0.2431 - acc: 0.9199
 2688/12231 [=====>........................] - ETA: 58s - loss: 0.2467 - acc: 0.9193
 2816/12231 [=====>........................] - ETA: 59s - loss: 0.2520 - acc: 0.9165
 2944/12231 [======>.......................] - ETA: 1:00 - loss: 0.2521 - acc: 0.9158
 3072/12231 [======>.......................] - ETA: 1:00 - loss: 0.2553 - acc: 0.9121
 3200/12231 [======>.......................] - ETA: 59s - loss: 0.2586 - acc: 0.9109 
 3328/12231 [=======>......................] - ETA: 57s - loss: 0.2593 - acc: 0.9105
 3456/12231 [=======>......................] - ETA: 57s - loss: 0.2603 - acc: 0.9103
 3584/12231 [=======>......................] - ETA: 56s - loss: 0.2601 - acc: 0.9099
 3712/12231 [========>.....................] - ETA: 55s - loss: 0.2595 - acc: 0.9108
 3840/12231 [========>.....................] - ETA: 54s - loss: 0.2611 - acc: 0.9104
 3968/12231 [========>.....................] - ETA: 53s - loss: 0.2631 - acc: 0.9093
 4096/12231 [=========>....................] - ETA: 52s - loss: 0.2647 - acc: 0.9087
 4224/12231 [=========>....................] - ETA: 52s - loss: 0.2676 - acc: 0.9074
 4352/12231 [=========>....................] - ETA: 51s - loss: 0.2698 - acc: 0.9069
 4480/12231 [=========>....................] - ETA: 51s - loss: 0.2688 - acc: 0.9074
 4608/12231 [==========>...................] - ETA: 50s - loss: 0.2678 - acc: 0.9076
 4736/12231 [==========>...................] - ETA: 49s - loss: 0.2669 - acc: 0.9077
 4864/12231 [==========>...................] - ETA: 48s - loss: 0.2681 - acc: 0.9071
 4992/12231 [===========>..................] - ETA: 47s - loss: 0.2688 - acc: 0.9071
 5120/12231 [===========>..................] - ETA: 46s - loss: 0.2676 - acc: 0.9074
 5248/12231 [===========>..................] - ETA: 45s - loss: 0.2650 - acc: 0.9085
 5376/12231 [============>.................] - ETA: 45s - loss: 0.2655 - acc: 0.9085
 5504/12231 [============>.................] - ETA: 44s - loss: 0.2655 - acc: 0.9084
 5632/12231 [============>.................] - ETA: 43s - loss: 0.2654 - acc: 0.9086
 5760/12231 [=============>................] - ETA: 42s - loss: 0.2644 - acc: 0.9087
 5888/12231 [=============>................] - ETA: 41s - loss: 0.2660 - acc: 0.9086
 6016/12231 [=============>................] - ETA: 40s - loss: 0.2660 - acc: 0.9091
 6144/12231 [==============>...............] - ETA: 39s - loss: 0.2651 - acc: 0.9095
 6272/12231 [==============>...............] - ETA: 38s - loss: 0.2631 - acc: 0.9102
 6400/12231 [==============>...............] - ETA: 37s - loss: 0.2627 - acc: 0.9106
 6528/12231 [===============>..............] - ETA: 36s - loss: 0.2638 - acc: 0.9104
 6656/12231 [===============>..............] - ETA: 35s - loss: 0.2629 - acc: 0.9103
 6784/12231 [===============>..............] - ETA: 34s - loss: 0.2624 - acc: 0.9099
 6912/12231 [===============>..............] - ETA: 34s - loss: 0.2611 - acc: 0.9110
 7040/12231 [================>.............] - ETA: 33s - loss: 0.2609 - acc: 0.9111
 7168/12231 [================>.............] - ETA: 32s - loss: 0.2625 - acc: 0.9104
 7296/12231 [================>.............] - ETA: 31s - loss: 0.2628 - acc: 0.9105
 7424/12231 [=================>............] - ETA: 30s - loss: 0.2639 - acc: 0.9104
 7552/12231 [=================>............] - ETA: 29s - loss: 0.2638 - acc: 0.9104
 7680/12231 [=================>............] - ETA: 28s - loss: 0.2621 - acc: 0.9113
 7808/12231 [==================>...........] - ETA: 27s - loss: 0.2621 - acc: 0.9118
 7936/12231 [==================>...........] - ETA: 26s - loss: 0.2625 - acc: 0.9115
 8064/12231 [==================>...........] - ETA: 26s - loss: 0.2630 - acc: 0.9113
 8192/12231 [===================>..........] - ETA: 25s - loss: 0.2629 - acc: 0.9114
 8320/12231 [===================>..........] - ETA: 24s - loss: 0.2622 - acc: 0.9114
 8448/12231 [===================>..........] - ETA: 23s - loss: 0.2631 - acc: 0.9107
 8576/12231 [====================>.........] - ETA: 22s - loss: 0.2627 - acc: 0.9109
 8704/12231 [====================>.........] - ETA: 21s - loss: 0.2626 - acc: 0.9107
 8832/12231 [====================>.........] - ETA: 21s - loss: 0.2640 - acc: 0.9099
 8960/12231 [====================>.........] - ETA: 20s - loss: 0.2644 - acc: 0.9097
 9088/12231 [=====================>........] - ETA: 19s - loss: 0.2650 - acc: 0.9098
 9216/12231 [=====================>........] - ETA: 18s - loss: 0.2655 - acc: 0.9097
 9344/12231 [=====================>........] - ETA: 17s - loss: 0.2659 - acc: 0.9095
 9472/12231 [======================>.......] - ETA: 17s - loss: 0.2666 - acc: 0.9091
 9600/12231 [======================>.......] - ETA: 16s - loss: 0.2671 - acc: 0.9087
 9728/12231 [======================>.......] - ETA: 15s - loss: 0.2676 - acc: 0.9079
 9856/12231 [=======================>......] - ETA: 14s - loss: 0.2676 - acc: 0.9078
 9984/12231 [=======================>......] - ETA: 14s - loss: 0.2686 - acc: 0.9075
10112/12231 [=======================>......] - ETA: 13s - loss: 0.2690 - acc: 0.9072
10240/12231 [========================>.....] - ETA: 12s - loss: 0.2691 - acc: 0.9073
10368/12231 [========================>.....] - ETA: 11s - loss: 0.2697 - acc: 0.9069
10496/12231 [========================>.....] - ETA: 11s - loss: 0.2694 - acc: 0.9070
10624/12231 [=========================>....] - ETA: 10s - loss: 0.2702 - acc: 0.9068
10752/12231 [=========================>....] - ETA: 9s - loss: 0.2697 - acc: 0.9071 
10880/12231 [=========================>....] - ETA: 8s - loss: 0.2692 - acc: 0.9073
11008/12231 [==========================>...] - ETA: 7s - loss: 0.2682 - acc: 0.9078
11136/12231 [==========================>...] - ETA: 7s - loss: 0.2680 - acc: 0.9080
11264/12231 [==========================>...] - ETA: 6s - loss: 0.2681 - acc: 0.9079
11392/12231 [==========================>...] - ETA: 5s - loss: 0.2677 - acc: 0.9081
11520/12231 [===========================>..] - ETA: 4s - loss: 0.2672 - acc: 0.9084
11648/12231 [===========================>..] - ETA: 3s - loss: 0.2674 - acc: 0.9083
11776/12231 [===========================>..] - ETA: 2s - loss: 0.2670 - acc: 0.9085
11904/12231 [============================>.] - ETA: 2s - loss: 0.2674 - acc: 0.9087
12032/12231 [============================>.] - ETA: 1s - loss: 0.2675 - acc: 0.9085
12160/12231 [============================>.] - ETA: 0s - loss: 0.2675 - acc: 0.9082
12231/12231 [==============================] - 82s 7ms/step - loss: 0.2678 - acc: 0.9080 - val_loss: 0.4360 - val_acc: 0.8587
Epoch 7/10

  128/12231 [..............................] - ETA: 1:28 - loss: 0.2057 - acc: 0.9141
  256/12231 [..............................] - ETA: 1:35 - loss: 0.2333 - acc: 0.9297
  384/12231 [..............................] - ETA: 1:33 - loss: 0.2140 - acc: 0.9401
  512/12231 [>.............................] - ETA: 1:26 - loss: 0.2154 - acc: 0.9434
  640/12231 [>.............................] - ETA: 1:20 - loss: 0.2387 - acc: 0.9313
  768/12231 [>.............................] - ETA: 1:17 - loss: 0.2354 - acc: 0.9258
  896/12231 [=>............................] - ETA: 1:14 - loss: 0.2383 - acc: 0.9241
 1024/12231 [=>............................] - ETA: 1:12 - loss: 0.2375 - acc: 0.9248
 1152/12231 [=>............................] - ETA: 1:12 - loss: 0.2258 - acc: 0.9314
 1280/12231 [==>...........................] - ETA: 1:14 - loss: 0.2246 - acc: 0.9305
 1408/12231 [==>...........................] - ETA: 1:13 - loss: 0.2248 - acc: 0.9268
 1536/12231 [==>...........................] - ETA: 1:12 - loss: 0.2243 - acc: 0.9258
 1664/12231 [===>..........................] - ETA: 1:11 - loss: 0.2285 - acc: 0.9267
 1792/12231 [===>..........................] - ETA: 1:10 - loss: 0.2273 - acc: 0.9275
 1920/12231 [===>..........................] - ETA: 1:11 - loss: 0.2245 - acc: 0.9276
 2048/12231 [====>.........................] - ETA: 1:09 - loss: 0.2301 - acc: 0.9253
 2176/12231 [====>.........................] - ETA: 1:07 - loss: 0.2347 - acc: 0.9237
 2304/12231 [====>.........................] - ETA: 1:06 - loss: 0.2338 - acc: 0.9232
 2432/12231 [====>.........................] - ETA: 1:05 - loss: 0.2329 - acc: 0.9231
 2560/12231 [=====>........................] - ETA: 1:05 - loss: 0.2334 - acc: 0.9230
 2688/12231 [=====>........................] - ETA: 1:04 - loss: 0.2303 - acc: 0.9241
 2816/12231 [=====>........................] - ETA: 1:02 - loss: 0.2333 - acc: 0.9222
 2944/12231 [======>.......................] - ETA: 1:02 - loss: 0.2352 - acc: 0.9222
 3072/12231 [======>.......................] - ETA: 1:02 - loss: 0.2365 - acc: 0.9219
 3200/12231 [======>.......................] - ETA: 1:02 - loss: 0.2368 - acc: 0.9219
 3328/12231 [=======>......................] - ETA: 1:02 - loss: 0.2363 - acc: 0.9222
 3456/12231 [=======>......................] - ETA: 1:02 - loss: 0.2359 - acc: 0.9227
 3584/12231 [=======>......................] - ETA: 1:02 - loss: 0.2349 - acc: 0.9230
 3712/12231 [========>.....................] - ETA: 1:01 - loss: 0.2324 - acc: 0.9238
 3840/12231 [========>.....................] - ETA: 59s - loss: 0.2294 - acc: 0.9255 
 3968/12231 [========>.....................] - ETA: 58s - loss: 0.2297 - acc: 0.9254
 4096/12231 [=========>....................] - ETA: 56s - loss: 0.2301 - acc: 0.9243
 4224/12231 [=========>....................] - ETA: 56s - loss: 0.2295 - acc: 0.9252
 4352/12231 [=========>....................] - ETA: 55s - loss: 0.2330 - acc: 0.9242
 4480/12231 [=========>....................] - ETA: 54s - loss: 0.2312 - acc: 0.9250
 4608/12231 [==========>...................] - ETA: 53s - loss: 0.2304 - acc: 0.9249
 4736/12231 [==========>...................] - ETA: 51s - loss: 0.2313 - acc: 0.9242
 4864/12231 [==========>...................] - ETA: 50s - loss: 0.2307 - acc: 0.9245
 4992/12231 [===========>..................] - ETA: 49s - loss: 0.2304 - acc: 0.9247
 5120/12231 [===========>..................] - ETA: 48s - loss: 0.2312 - acc: 0.9234
 5248/12231 [===========>..................] - ETA: 47s - loss: 0.2293 - acc: 0.9244
 5376/12231 [============>.................] - ETA: 46s - loss: 0.2282 - acc: 0.9250
 5504/12231 [============>.................] - ETA: 45s - loss: 0.2273 - acc: 0.9253
 5632/12231 [============>.................] - ETA: 45s - loss: 0.2285 - acc: 0.9244
 5760/12231 [=============>................] - ETA: 44s - loss: 0.2274 - acc: 0.9243
 5888/12231 [=============>................] - ETA: 43s - loss: 0.2261 - acc: 0.9253
 6016/12231 [=============>................] - ETA: 43s - loss: 0.2271 - acc: 0.9247
 6144/12231 [==============>...............] - ETA: 42s - loss: 0.2266 - acc: 0.9250
 6272/12231 [==============>...............] - ETA: 41s - loss: 0.2269 - acc: 0.9249
 6400/12231 [==============>...............] - ETA: 40s - loss: 0.2278 - acc: 0.9242
 6528/12231 [===============>..............] - ETA: 40s - loss: 0.2267 - acc: 0.9243
 6656/12231 [===============>..............] - ETA: 39s - loss: 0.2259 - acc: 0.9247
 6784/12231 [===============>..............] - ETA: 38s - loss: 0.2248 - acc: 0.9250
 6912/12231 [===============>..............] - ETA: 37s - loss: 0.2242 - acc: 0.9253
 7040/12231 [================>.............] - ETA: 37s - loss: 0.2234 - acc: 0.9254
 7168/12231 [================>.............] - ETA: 36s - loss: 0.2237 - acc: 0.9256
 7296/12231 [================>.............] - ETA: 35s - loss: 0.2232 - acc: 0.9257
 7424/12231 [=================>............] - ETA: 34s - loss: 0.2237 - acc: 0.9252
 7552/12231 [=================>............] - ETA: 33s - loss: 0.2250 - acc: 0.9243
 7680/12231 [=================>............] - ETA: 32s - loss: 0.2258 - acc: 0.9241
 7808/12231 [==================>...........] - ETA: 31s - loss: 0.2262 - acc: 0.9242
 7936/12231 [==================>...........] - ETA: 30s - loss: 0.2268 - acc: 0.9241
 8064/12231 [==================>...........] - ETA: 29s - loss: 0.2260 - acc: 0.9244
 8192/12231 [===================>..........] - ETA: 28s - loss: 0.2261 - acc: 0.9246
 8320/12231 [===================>..........] - ETA: 27s - loss: 0.2265 - acc: 0.9243
 8448/12231 [===================>..........] - ETA: 26s - loss: 0.2261 - acc: 0.9242
 8576/12231 [====================>.........] - ETA: 25s - loss: 0.2268 - acc: 0.9240
 8704/12231 [====================>.........] - ETA: 24s - loss: 0.2267 - acc: 0.9241
 8832/12231 [====================>.........] - ETA: 23s - loss: 0.2272 - acc: 0.9236
 8960/12231 [====================>.........] - ETA: 22s - loss: 0.2269 - acc: 0.9235
 9088/12231 [=====================>........] - ETA: 21s - loss: 0.2270 - acc: 0.9236
 9216/12231 [=====================>........] - ETA: 20s - loss: 0.2264 - acc: 0.9239
 9344/12231 [=====================>........] - ETA: 19s - loss: 0.2250 - acc: 0.9243
 9472/12231 [======================>.......] - ETA: 18s - loss: 0.2255 - acc: 0.9244
 9600/12231 [======================>.......] - ETA: 17s - loss: 0.2259 - acc: 0.9242
 9728/12231 [======================>.......] - ETA: 17s - loss: 0.2262 - acc: 0.9239
 9856/12231 [=======================>......] - ETA: 16s - loss: 0.2256 - acc: 0.9243
 9984/12231 [=======================>......] - ETA: 15s - loss: 0.2262 - acc: 0.9239
10112/12231 [=======================>......] - ETA: 14s - loss: 0.2271 - acc: 0.9233
10240/12231 [========================>.....] - ETA: 13s - loss: 0.2266 - acc: 0.9235
10368/12231 [========================>.....] - ETA: 12s - loss: 0.2265 - acc: 0.9236
10496/12231 [========================>.....] - ETA: 11s - loss: 0.2264 - acc: 0.9236
10624/12231 [=========================>....] - ETA: 10s - loss: 0.2273 - acc: 0.9228
10752/12231 [=========================>....] - ETA: 9s - loss: 0.2267 - acc: 0.9231 
10880/12231 [=========================>....] - ETA: 8s - loss: 0.2258 - acc: 0.9233
11008/12231 [==========================>...] - ETA: 8s - loss: 0.2250 - acc: 0.9238
11136/12231 [==========================>...] - ETA: 7s - loss: 0.2246 - acc: 0.9238
11264/12231 [==========================>...] - ETA: 6s - loss: 0.2248 - acc: 0.9235
11392/12231 [==========================>...] - ETA: 5s - loss: 0.2246 - acc: 0.9234
11520/12231 [===========================>..] - ETA: 4s - loss: 0.2249 - acc: 0.9234
11648/12231 [===========================>..] - ETA: 3s - loss: 0.2249 - acc: 0.9236
11776/12231 [===========================>..] - ETA: 2s - loss: 0.2245 - acc: 0.9238
11904/12231 [============================>.] - ETA: 2s - loss: 0.2246 - acc: 0.9237
12032/12231 [============================>.] - ETA: 1s - loss: 0.2249 - acc: 0.9237
12160/12231 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9238
12231/12231 [==============================] - 82s 7ms/step - loss: 0.2245 - acc: 0.9240 - val_loss: 0.4401 - val_acc: 0.8565
Epoch 8/10

  128/12231 [..............................] - ETA: 1:01 - loss: 0.2242 - acc: 0.9219
  256/12231 [..............................] - ETA: 1:01 - loss: 0.2292 - acc: 0.9297
  384/12231 [..............................] - ETA: 1:02 - loss: 0.1970 - acc: 0.9427
  512/12231 [>.............................] - ETA: 1:01 - loss: 0.1784 - acc: 0.9492
  640/12231 [>.............................] - ETA: 1:00 - loss: 0.1735 - acc: 0.9469
  768/12231 [>.............................] - ETA: 59s - loss: 0.1707 - acc: 0.9492 
  896/12231 [=>............................] - ETA: 58s - loss: 0.1711 - acc: 0.9498
 1024/12231 [=>............................] - ETA: 58s - loss: 0.1694 - acc: 0.9521
 1152/12231 [=>............................] - ETA: 58s - loss: 0.1655 - acc: 0.9531
 1280/12231 [==>...........................] - ETA: 58s - loss: 0.1619 - acc: 0.9539
 1408/12231 [==>...........................] - ETA: 57s - loss: 0.1623 - acc: 0.9545
 1536/12231 [==>...........................] - ETA: 56s - loss: 0.1658 - acc: 0.9557
 1664/12231 [===>..........................] - ETA: 56s - loss: 0.1667 - acc: 0.9531
 1792/12231 [===>..........................] - ETA: 55s - loss: 0.1685 - acc: 0.9531
 1920/12231 [===>..........................] - ETA: 56s - loss: 0.1687 - acc: 0.9510
 2048/12231 [====>.........................] - ETA: 56s - loss: 0.1699 - acc: 0.9507
 2176/12231 [====>.........................] - ETA: 56s - loss: 0.1660 - acc: 0.9522
 2304/12231 [====>.........................] - ETA: 56s - loss: 0.1645 - acc: 0.9518
 2432/12231 [====>.........................] - ETA: 57s - loss: 0.1641 - acc: 0.9511
 2560/12231 [=====>........................] - ETA: 57s - loss: 0.1627 - acc: 0.9512
 2688/12231 [=====>........................] - ETA: 56s - loss: 0.1622 - acc: 0.9516
 2816/12231 [=====>........................] - ETA: 56s - loss: 0.1606 - acc: 0.9517
 2944/12231 [======>.......................] - ETA: 56s - loss: 0.1612 - acc: 0.9514
 3072/12231 [======>.......................] - ETA: 56s - loss: 0.1627 - acc: 0.9508
 3200/12231 [======>.......................] - ETA: 56s - loss: 0.1614 - acc: 0.9506
 3328/12231 [=======>......................] - ETA: 56s - loss: 0.1678 - acc: 0.9477
 3456/12231 [=======>......................] - ETA: 55s - loss: 0.1702 - acc: 0.9468
 3584/12231 [=======>......................] - ETA: 54s - loss: 0.1708 - acc: 0.9464
 3712/12231 [========>.....................] - ETA: 53s - loss: 0.1715 - acc: 0.9464
 3840/12231 [========>.....................] - ETA: 52s - loss: 0.1708 - acc: 0.9464
 3968/12231 [========>.....................] - ETA: 51s - loss: 0.1695 - acc: 0.9476
 4096/12231 [=========>....................] - ETA: 50s - loss: 0.1684 - acc: 0.9478
 4224/12231 [=========>....................] - ETA: 49s - loss: 0.1706 - acc: 0.9460
 4352/12231 [=========>....................] - ETA: 48s - loss: 0.1702 - acc: 0.9460
 4480/12231 [=========>....................] - ETA: 47s - loss: 0.1717 - acc: 0.9455
 4608/12231 [==========>...................] - ETA: 46s - loss: 0.1720 - acc: 0.9457
 4736/12231 [==========>...................] - ETA: 45s - loss: 0.1748 - acc: 0.9440
 4864/12231 [==========>...................] - ETA: 44s - loss: 0.1760 - acc: 0.9433
 4992/12231 [===========>..................] - ETA: 43s - loss: 0.1761 - acc: 0.9435
 5120/12231 [===========>..................] - ETA: 42s - loss: 0.1770 - acc: 0.9430
 5248/12231 [===========>..................] - ETA: 42s - loss: 0.1790 - acc: 0.9421
 5376/12231 [============>.................] - ETA: 41s - loss: 0.1806 - acc: 0.9414
 5504/12231 [============>.................] - ETA: 40s - loss: 0.1820 - acc: 0.9404
 5632/12231 [============>.................] - ETA: 39s - loss: 0.1819 - acc: 0.9407
 5760/12231 [=============>................] - ETA: 38s - loss: 0.1829 - acc: 0.9398
 5888/12231 [=============>................] - ETA: 38s - loss: 0.1835 - acc: 0.9394
 6016/12231 [=============>................] - ETA: 37s - loss: 0.1836 - acc: 0.9395
 6144/12231 [==============>...............] - ETA: 36s - loss: 0.1846 - acc: 0.9395
 6272/12231 [==============>...............] - ETA: 36s - loss: 0.1857 - acc: 0.9391
 6400/12231 [==============>...............] - ETA: 35s - loss: 0.1848 - acc: 0.9398
 6528/12231 [===============>..............] - ETA: 34s - loss: 0.1844 - acc: 0.9401
 6656/12231 [===============>..............] - ETA: 33s - loss: 0.1842 - acc: 0.9402
 6784/12231 [===============>..............] - ETA: 33s - loss: 0.1858 - acc: 0.9394
 6912/12231 [===============>..............] - ETA: 32s - loss: 0.1854 - acc: 0.9397
 7040/12231 [================>.............] - ETA: 31s - loss: 0.1856 - acc: 0.9392
 7168/12231 [================>.............] - ETA: 31s - loss: 0.1861 - acc: 0.9393
 7296/12231 [================>.............] - ETA: 30s - loss: 0.1859 - acc: 0.9391
 7424/12231 [=================>............] - ETA: 29s - loss: 0.1851 - acc: 0.9393
 7552/12231 [=================>............] - ETA: 29s - loss: 0.1849 - acc: 0.9394
 7680/12231 [=================>............] - ETA: 28s - loss: 0.1843 - acc: 0.9395
 7808/12231 [==================>...........] - ETA: 28s - loss: 0.1858 - acc: 0.9390
 7936/12231 [==================>...........] - ETA: 27s - loss: 0.1862 - acc: 0.9386
 8064/12231 [==================>...........] - ETA: 26s - loss: 0.1853 - acc: 0.9390
 8192/12231 [===================>..........] - ETA: 25s - loss: 0.1847 - acc: 0.9395
 8320/12231 [===================>..........] - ETA: 24s - loss: 0.1863 - acc: 0.9389
 8448/12231 [===================>..........] - ETA: 23s - loss: 0.1866 - acc: 0.9388
 8576/12231 [====================>.........] - ETA: 23s - loss: 0.1864 - acc: 0.9389
 8704/12231 [====================>.........] - ETA: 22s - loss: 0.1858 - acc: 0.9392
 8832/12231 [====================>.........] - ETA: 21s - loss: 0.1852 - acc: 0.9392
 8960/12231 [====================>.........] - ETA: 20s - loss: 0.1855 - acc: 0.9392
 9088/12231 [=====================>........] - ETA: 19s - loss: 0.1861 - acc: 0.9388
 9216/12231 [=====================>........] - ETA: 18s - loss: 0.1858 - acc: 0.9388
 9344/12231 [=====================>........] - ETA: 18s - loss: 0.1863 - acc: 0.9388
 9472/12231 [======================>.......] - ETA: 17s - loss: 0.1871 - acc: 0.9383
 9600/12231 [======================>.......] - ETA: 16s - loss: 0.1881 - acc: 0.9381
 9728/12231 [======================>.......] - ETA: 15s - loss: 0.1881 - acc: 0.9379
 9856/12231 [=======================>......] - ETA: 15s - loss: 0.1884 - acc: 0.9376
 9984/12231 [=======================>......] - ETA: 14s - loss: 0.1888 - acc: 0.9374
10112/12231 [=======================>......] - ETA: 13s - loss: 0.1890 - acc: 0.9371
10240/12231 [========================>.....] - ETA: 12s - loss: 0.1884 - acc: 0.9372
10368/12231 [========================>.....] - ETA: 11s - loss: 0.1895 - acc: 0.9368
10496/12231 [========================>.....] - ETA: 10s - loss: 0.1904 - acc: 0.9365
10624/12231 [=========================>....] - ETA: 10s - loss: 0.1911 - acc: 0.9360
10752/12231 [=========================>....] - ETA: 9s - loss: 0.1910 - acc: 0.9361 
10880/12231 [=========================>....] - ETA: 8s - loss: 0.1909 - acc: 0.9361
11008/12231 [==========================>...] - ETA: 7s - loss: 0.1914 - acc: 0.9360
11136/12231 [==========================>...] - ETA: 6s - loss: 0.1910 - acc: 0.9362
11264/12231 [==========================>...] - ETA: 5s - loss: 0.1908 - acc: 0.9361
11392/12231 [==========================>...] - ETA: 5s - loss: 0.1914 - acc: 0.9357
11520/12231 [===========================>..] - ETA: 4s - loss: 0.1918 - acc: 0.9357
11648/12231 [===========================>..] - ETA: 3s - loss: 0.1922 - acc: 0.9354
11776/12231 [===========================>..] - ETA: 2s - loss: 0.1928 - acc: 0.9352
11904/12231 [============================>.] - ETA: 2s - loss: 0.1926 - acc: 0.9354
12032/12231 [============================>.] - ETA: 1s - loss: 0.1925 - acc: 0.9357
12160/12231 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9352
12231/12231 [==============================] - 77s 6ms/step - loss: 0.1932 - acc: 0.9351 - val_loss: 0.3756 - val_acc: 0.8683
Epoch 9/10

  128/12231 [..............................] - ETA: 1:16 - loss: 0.1327 - acc: 0.9609
  256/12231 [..............................] - ETA: 1:17 - loss: 0.1573 - acc: 0.9531
  384/12231 [..............................] - ETA: 1:17 - loss: 0.1522 - acc: 0.9557
  512/12231 [>.............................] - ETA: 1:19 - loss: 0.1666 - acc: 0.9473
  640/12231 [>.............................] - ETA: 1:20 - loss: 0.1807 - acc: 0.9391
  768/12231 [>.............................] - ETA: 1:19 - loss: 0.1713 - acc: 0.9414
  896/12231 [=>............................] - ETA: 1:18 - loss: 0.1690 - acc: 0.9431
 1024/12231 [=>............................] - ETA: 1:16 - loss: 0.1613 - acc: 0.9473
 1152/12231 [=>............................] - ETA: 1:14 - loss: 0.1607 - acc: 0.9462
 1280/12231 [==>...........................] - ETA: 1:12 - loss: 0.1583 - acc: 0.9461
 1408/12231 [==>...........................] - ETA: 1:10 - loss: 0.1594 - acc: 0.9467
 1536/12231 [==>...........................] - ETA: 1:10 - loss: 0.1621 - acc: 0.9466
 1664/12231 [===>..........................] - ETA: 1:10 - loss: 0.1605 - acc: 0.9477
 1792/12231 [===>..........................] - ETA: 1:09 - loss: 0.1628 - acc: 0.9470
 1920/12231 [===>..........................] - ETA: 1:10 - loss: 0.1642 - acc: 0.9453
 2048/12231 [====>.........................] - ETA: 1:09 - loss: 0.1619 - acc: 0.9453
 2176/12231 [====>.........................] - ETA: 1:08 - loss: 0.1670 - acc: 0.9444
 2304/12231 [====>.........................] - ETA: 1:09 - loss: 0.1669 - acc: 0.9436
 2432/12231 [====>.........................] - ETA: 1:09 - loss: 0.1672 - acc: 0.9424
 2560/12231 [=====>........................] - ETA: 1:08 - loss: 0.1665 - acc: 0.9426
 2688/12231 [=====>........................] - ETA: 1:06 - loss: 0.1671 - acc: 0.9427
 2816/12231 [=====>........................] - ETA: 1:05 - loss: 0.1652 - acc: 0.9435
 2944/12231 [======>.......................] - ETA: 1:05 - loss: 0.1664 - acc: 0.9443
 3072/12231 [======>.......................] - ETA: 1:04 - loss: 0.1659 - acc: 0.9443
 3200/12231 [======>.......................] - ETA: 1:03 - loss: 0.1663 - acc: 0.9441
 3328/12231 [=======>......................] - ETA: 1:03 - loss: 0.1673 - acc: 0.9429
 3456/12231 [=======>......................] - ETA: 1:02 - loss: 0.1668 - acc: 0.9421
 3584/12231 [=======>......................] - ETA: 1:01 - loss: 0.1673 - acc: 0.9411
 3712/12231 [========>.....................] - ETA: 1:00 - loss: 0.1679 - acc: 0.9407
 3840/12231 [========>.....................] - ETA: 59s - loss: 0.1655 - acc: 0.9424 
 3968/12231 [========>.....................] - ETA: 58s - loss: 0.1659 - acc: 0.9423
 4096/12231 [=========>....................] - ETA: 57s - loss: 0.1654 - acc: 0.9424
 4224/12231 [=========>....................] - ETA: 55s - loss: 0.1678 - acc: 0.9413
 4352/12231 [=========>....................] - ETA: 54s - loss: 0.1698 - acc: 0.9400
 4480/12231 [=========>....................] - ETA: 53s - loss: 0.1706 - acc: 0.9404
 4608/12231 [==========>...................] - ETA: 51s - loss: 0.1727 - acc: 0.9395
 4736/12231 [==========>...................] - ETA: 51s - loss: 0.1741 - acc: 0.9383
 4864/12231 [==========>...................] - ETA: 50s - loss: 0.1745 - acc: 0.9387
 4992/12231 [===========>..................] - ETA: 49s - loss: 0.1752 - acc: 0.9387
 5120/12231 [===========>..................] - ETA: 48s - loss: 0.1745 - acc: 0.9385
 5248/12231 [===========>..................] - ETA: 47s - loss: 0.1752 - acc: 0.9375
 5376/12231 [============>.................] - ETA: 47s - loss: 0.1759 - acc: 0.9375
 5504/12231 [============>.................] - ETA: 45s - loss: 0.1754 - acc: 0.9377
 5632/12231 [============>.................] - ETA: 44s - loss: 0.1754 - acc: 0.9380
 5760/12231 [=============>................] - ETA: 43s - loss: 0.1772 - acc: 0.9377
 5888/12231 [=============>................] - ETA: 42s - loss: 0.1760 - acc: 0.9385
 6016/12231 [=============>................] - ETA: 41s - loss: 0.1760 - acc: 0.9380
 6144/12231 [==============>...............] - ETA: 41s - loss: 0.1757 - acc: 0.9380
 6272/12231 [==============>...............] - ETA: 40s - loss: 0.1764 - acc: 0.9380
 6400/12231 [==============>...............] - ETA: 39s - loss: 0.1761 - acc: 0.9380
 6528/12231 [===============>..............] - ETA: 38s - loss: 0.1758 - acc: 0.9380
 6656/12231 [===============>..............] - ETA: 37s - loss: 0.1756 - acc: 0.9380
 6784/12231 [===============>..............] - ETA: 36s - loss: 0.1748 - acc: 0.9381
 6912/12231 [===============>..............] - ETA: 36s - loss: 0.1742 - acc: 0.9379
 7040/12231 [================>.............] - ETA: 35s - loss: 0.1738 - acc: 0.9378
 7168/12231 [================>.............] - ETA: 34s - loss: 0.1732 - acc: 0.9381
 7296/12231 [================>.............] - ETA: 33s - loss: 0.1725 - acc: 0.9383
 7424/12231 [=================>............] - ETA: 32s - loss: 0.1741 - acc: 0.9376
 7552/12231 [=================>............] - ETA: 31s - loss: 0.1722 - acc: 0.9384
 7680/12231 [=================>............] - ETA: 30s - loss: 0.1719 - acc: 0.9383
 7808/12231 [==================>...........] - ETA: 30s - loss: 0.1713 - acc: 0.9385
 7936/12231 [==================>...........] - ETA: 29s - loss: 0.1720 - acc: 0.9379
 8064/12231 [==================>...........] - ETA: 28s - loss: 0.1734 - acc: 0.9375
 8192/12231 [===================>..........] - ETA: 27s - loss: 0.1728 - acc: 0.9379
 8320/12231 [===================>..........] - ETA: 27s - loss: 0.1723 - acc: 0.9383
 8448/12231 [===================>..........] - ETA: 26s - loss: 0.1715 - acc: 0.9387
 8576/12231 [====================>.........] - ETA: 25s - loss: 0.1703 - acc: 0.9392
 8704/12231 [====================>.........] - ETA: 24s - loss: 0.1701 - acc: 0.9393
 8832/12231 [====================>.........] - ETA: 23s - loss: 0.1702 - acc: 0.9392
 8960/12231 [====================>.........] - ETA: 22s - loss: 0.1694 - acc: 0.9394
 9088/12231 [=====================>........] - ETA: 22s - loss: 0.1693 - acc: 0.9394
 9216/12231 [=====================>........] - ETA: 21s - loss: 0.1690 - acc: 0.9393
 9344/12231 [=====================>........] - ETA: 20s - loss: 0.1682 - acc: 0.9397
 9472/12231 [======================>.......] - ETA: 19s - loss: 0.1679 - acc: 0.9399
 9600/12231 [======================>.......] - ETA: 18s - loss: 0.1684 - acc: 0.9396
 9728/12231 [======================>.......] - ETA: 18s - loss: 0.1674 - acc: 0.9401
 9856/12231 [=======================>......] - ETA: 17s - loss: 0.1672 - acc: 0.9399
 9984/12231 [=======================>......] - ETA: 16s - loss: 0.1668 - acc: 0.9401
10112/12231 [=======================>......] - ETA: 15s - loss: 0.1681 - acc: 0.9397
10240/12231 [========================>.....] - ETA: 14s - loss: 0.1679 - acc: 0.9396
10368/12231 [========================>.....] - ETA: 13s - loss: 0.1676 - acc: 0.9397
10496/12231 [========================>.....] - ETA: 12s - loss: 0.1668 - acc: 0.9401
10624/12231 [=========================>....] - ETA: 11s - loss: 0.1664 - acc: 0.9401
10752/12231 [=========================>....] - ETA: 10s - loss: 0.1667 - acc: 0.9399
10880/12231 [=========================>....] - ETA: 9s - loss: 0.1669 - acc: 0.9399 
11008/12231 [==========================>...] - ETA: 8s - loss: 0.1670 - acc: 0.9399
11136/12231 [==========================>...] - ETA: 7s - loss: 0.1672 - acc: 0.9399
11264/12231 [==========================>...] - ETA: 6s - loss: 0.1676 - acc: 0.9399
11392/12231 [==========================>...] - ETA: 5s - loss: 0.1670 - acc: 0.9403
11520/12231 [===========================>..] - ETA: 4s - loss: 0.1672 - acc: 0.9403
11648/12231 [===========================>..] - ETA: 4s - loss: 0.1669 - acc: 0.9403
11776/12231 [===========================>..] - ETA: 3s - loss: 0.1665 - acc: 0.9406
11904/12231 [============================>.] - ETA: 2s - loss: 0.1661 - acc: 0.9409
12032/12231 [============================>.] - ETA: 1s - loss: 0.1657 - acc: 0.9408
12160/12231 [============================>.] - ETA: 0s - loss: 0.1660 - acc: 0.9407
12231/12231 [==============================] - 86s 7ms/step - loss: 0.1658 - acc: 0.9409 - val_loss: 0.4059 - val_acc: 0.8742
Epoch 10/10

  128/12231 [..............................] - ETA: 1:03 - loss: 0.1088 - acc: 0.9766
  256/12231 [..............................] - ETA: 1:03 - loss: 0.1109 - acc: 0.9727
  384/12231 [..............................] - ETA: 1:02 - loss: 0.1052 - acc: 0.9740
  512/12231 [>.............................] - ETA: 1:02 - loss: 0.1137 - acc: 0.9688
  640/12231 [>.............................] - ETA: 1:01 - loss: 0.1247 - acc: 0.9625
  768/12231 [>.............................] - ETA: 1:01 - loss: 0.1232 - acc: 0.9596
  896/12231 [=>............................] - ETA: 1:00 - loss: 0.1237 - acc: 0.9598
 1024/12231 [=>............................] - ETA: 59s - loss: 0.1301 - acc: 0.9561 
 1152/12231 [=>............................] - ETA: 59s - loss: 0.1350 - acc: 0.9540
 1280/12231 [==>...........................] - ETA: 58s - loss: 0.1402 - acc: 0.9508
 1408/12231 [==>...........................] - ETA: 58s - loss: 0.1366 - acc: 0.9531
 1536/12231 [==>...........................] - ETA: 57s - loss: 0.1371 - acc: 0.9512
 1664/12231 [===>..........................] - ETA: 56s - loss: 0.1372 - acc: 0.9513
 1792/12231 [===>..........................] - ETA: 55s - loss: 0.1403 - acc: 0.9492
 1920/12231 [===>..........................] - ETA: 55s - loss: 0.1425 - acc: 0.9479
 2048/12231 [====>.........................] - ETA: 54s - loss: 0.1408 - acc: 0.9482
 2176/12231 [====>.........................] - ETA: 53s - loss: 0.1434 - acc: 0.9485
 2304/12231 [====>.........................] - ETA: 53s - loss: 0.1418 - acc: 0.9497
 2432/12231 [====>.........................] - ETA: 52s - loss: 0.1416 - acc: 0.9498
 2560/12231 [=====>........................] - ETA: 52s - loss: 0.1390 - acc: 0.9508
 2688/12231 [=====>........................] - ETA: 51s - loss: 0.1414 - acc: 0.9494
 2816/12231 [=====>........................] - ETA: 50s - loss: 0.1403 - acc: 0.9506
 2944/12231 [======>.......................] - ETA: 50s - loss: 0.1397 - acc: 0.9507
 3072/12231 [======>.......................] - ETA: 49s - loss: 0.1377 - acc: 0.9508
 3200/12231 [======>.......................] - ETA: 49s - loss: 0.1375 - acc: 0.9509
 3328/12231 [=======>......................] - ETA: 49s - loss: 0.1372 - acc: 0.9513
 3456/12231 [=======>......................] - ETA: 48s - loss: 0.1361 - acc: 0.9517
 3584/12231 [=======>......................] - ETA: 47s - loss: 0.1356 - acc: 0.9526
 3712/12231 [========>.....................] - ETA: 47s - loss: 0.1350 - acc: 0.9526
 3840/12231 [========>.....................] - ETA: 46s - loss: 0.1347 - acc: 0.9526
 3968/12231 [========>.....................] - ETA: 45s - loss: 0.1334 - acc: 0.9529
 4096/12231 [=========>....................] - ETA: 45s - loss: 0.1338 - acc: 0.9521
 4224/12231 [=========>....................] - ETA: 45s - loss: 0.1334 - acc: 0.9519
 4352/12231 [=========>....................] - ETA: 44s - loss: 0.1349 - acc: 0.9520
 4480/12231 [=========>....................] - ETA: 44s - loss: 0.1358 - acc: 0.9520
 4608/12231 [==========>...................] - ETA: 43s - loss: 0.1372 - acc: 0.9512
 4736/12231 [==========>...................] - ETA: 43s - loss: 0.1369 - acc: 0.9516
 4864/12231 [==========>...................] - ETA: 42s - loss: 0.1348 - acc: 0.9527
 4992/12231 [===========>..................] - ETA: 42s - loss: 0.1359 - acc: 0.9525
 5120/12231 [===========>..................] - ETA: 41s - loss: 0.1344 - acc: 0.9533
 5248/12231 [===========>..................] - ETA: 41s - loss: 0.1335 - acc: 0.9539
 5376/12231 [============>.................] - ETA: 40s - loss: 0.1333 - acc: 0.9541
 5504/12231 [============>.................] - ETA: 40s - loss: 0.1322 - acc: 0.9548
 5632/12231 [============>.................] - ETA: 39s - loss: 0.1323 - acc: 0.9544
 5760/12231 [=============>................] - ETA: 38s - loss: 0.1323 - acc: 0.9542
 5888/12231 [=============>................] - ETA: 38s - loss: 0.1321 - acc: 0.9545
 6016/12231 [=============>................] - ETA: 37s - loss: 0.1323 - acc: 0.9543
 6144/12231 [==============>...............] - ETA: 37s - loss: 0.1314 - acc: 0.9549
 6272/12231 [==============>...............] - ETA: 36s - loss: 0.1314 - acc: 0.9552
 6400/12231 [==============>...............] - ETA: 35s - loss: 0.1305 - acc: 0.9556
 6528/12231 [===============>..............] - ETA: 34s - loss: 0.1329 - acc: 0.9547
 6656/12231 [===============>..............] - ETA: 33s - loss: 0.1333 - acc: 0.9546
 6784/12231 [===============>..............] - ETA: 32s - loss: 0.1332 - acc: 0.9549
 6912/12231 [===============>..............] - ETA: 32s - loss: 0.1334 - acc: 0.9549
 7040/12231 [================>.............] - ETA: 31s - loss: 0.1341 - acc: 0.9548
 7168/12231 [================>.............] - ETA: 30s - loss: 0.1350 - acc: 0.9547
 7296/12231 [================>.............] - ETA: 29s - loss: 0.1341 - acc: 0.9550
 7424/12231 [=================>............] - ETA: 29s - loss: 0.1347 - acc: 0.9545
 7552/12231 [=================>............] - ETA: 28s - loss: 0.1349 - acc: 0.9544
 7680/12231 [=================>............] - ETA: 27s - loss: 0.1350 - acc: 0.9542
 7808/12231 [==================>...........] - ETA: 26s - loss: 0.1344 - acc: 0.9543
 7936/12231 [==================>...........] - ETA: 26s - loss: 0.1349 - acc: 0.9543
 8064/12231 [==================>...........] - ETA: 25s - loss: 0.1352 - acc: 0.9542
 8192/12231 [===================>..........] - ETA: 24s - loss: 0.1360 - acc: 0.9537
 8320/12231 [===================>..........] - ETA: 23s - loss: 0.1354 - acc: 0.9538
 8448/12231 [===================>..........] - ETA: 22s - loss: 0.1349 - acc: 0.9543
 8576/12231 [====================>.........] - ETA: 21s - loss: 0.1343 - acc: 0.9544
 8704/12231 [====================>.........] - ETA: 21s - loss: 0.1340 - acc: 0.9544
 8832/12231 [====================>.........] - ETA: 20s - loss: 0.1340 - acc: 0.9545
 8960/12231 [====================>.........] - ETA: 19s - loss: 0.1342 - acc: 0.9544
 9088/12231 [=====================>........] - ETA: 18s - loss: 0.1341 - acc: 0.9544
 9216/12231 [=====================>........] - ETA: 17s - loss: 0.1339 - acc: 0.9548
 9344/12231 [=====================>........] - ETA: 17s - loss: 0.1342 - acc: 0.9544
 9472/12231 [======================>.......] - ETA: 16s - loss: 0.1337 - acc: 0.9547
 9600/12231 [======================>.......] - ETA: 15s - loss: 0.1342 - acc: 0.9548
 9728/12231 [======================>.......] - ETA: 14s - loss: 0.1347 - acc: 0.9544
 9856/12231 [=======================>......] - ETA: 13s - loss: 0.1346 - acc: 0.9542
 9984/12231 [=======================>......] - ETA: 13s - loss: 0.1351 - acc: 0.9542
10112/12231 [=======================>......] - ETA: 12s - loss: 0.1358 - acc: 0.9541
10240/12231 [========================>.....] - ETA: 11s - loss: 0.1363 - acc: 0.9540
10368/12231 [========================>.....] - ETA: 10s - loss: 0.1359 - acc: 0.9543
10496/12231 [========================>.....] - ETA: 10s - loss: 0.1370 - acc: 0.9539
10624/12231 [=========================>....] - ETA: 9s - loss: 0.1371 - acc: 0.9539 
10752/12231 [=========================>....] - ETA: 8s - loss: 0.1369 - acc: 0.9541
10880/12231 [=========================>....] - ETA: 7s - loss: 0.1372 - acc: 0.9538
11008/12231 [==========================>...] - ETA: 7s - loss: 0.1370 - acc: 0.9539
11136/12231 [==========================>...] - ETA: 6s - loss: 0.1371 - acc: 0.9538
11264/12231 [==========================>...] - ETA: 5s - loss: 0.1376 - acc: 0.9534
11392/12231 [==========================>...] - ETA: 4s - loss: 0.1374 - acc: 0.9534
11520/12231 [===========================>..] - ETA: 4s - loss: 0.1380 - acc: 0.9534
11648/12231 [===========================>..] - ETA: 3s - loss: 0.1384 - acc: 0.9534
11776/12231 [===========================>..] - ETA: 2s - loss: 0.1388 - acc: 0.9533
11904/12231 [============================>.] - ETA: 1s - loss: 0.1383 - acc: 0.9537
12032/12231 [============================>.] - ETA: 1s - loss: 0.1388 - acc: 0.9535
12160/12231 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9535
12231/12231 [==============================] - 72s 6ms/step - loss: 0.1391 - acc: 0.9537 - val_loss: 0.4152 - val_acc: 0.8683
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 200)           2000200   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               935936    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 3,986,761
Trainable params: 3,986,761
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
the affordable care act is terrible 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
the affordable care act is terrible 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
the affordable care act is terrible 
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     3    1  501   40  375   15 1999    4]]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.50050855]]
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.50200295]]
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.49996668]]
model loaded
the affordable care act is terrible 
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     3    1  501   40  375   15 1999    4]]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.49837127]]
model loaded
the affordable care act is terrible 
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     3    1  501   40  375   15 1999    4]]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.49900326]]
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.04403111]]
model loaded
the affordable care act is terrible 
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     3    1  501   40  375   15 1999    4]]
the affordable care act is terrible 
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     3    1  501   40  375   15 1999    4]]
the terrible affordable care act is terrible 
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    3
     1 1999  501   40  375   15 1999    4]]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.04403111]]
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.04403111]]
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
computing
[[0.04403111]]
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 50)                0         
_________________________________________________________________
embedding (Embedding)        (None, 50, 100)           1000100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 512)               731136    
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
prediction (Dense)           (None, 1)                 513       
=================================================================
Total params: 2,781,861
Trainable params: 2,781,861
Non-trainable params: 0
_________________________________________________________________
model loaded
